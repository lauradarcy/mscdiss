\chapter{Introduction}

Distributed systems can be defined as: `a collection of autonomous computing elements that can appear to its users as a single coherent system' \cite{vanSteen2016}. Distributed systems are used in a wide variety of applications, including P2P networks, cluster computing, large financial systems, and CCTV networks. As these systems are composed of a large number of individual components, the order of accessing these separate services, or the workflow, is very important to the efficacy and efficiency of achieving the desired task. Tracking a specific car through a large CCTV network, for example, would be extremely time consuming to do manually. Automated workflow construction is therefore an important open question in the area of distributed systems. 

One potential solution to the automated workflow question is the use of reinforcement learning. Reinforcement learning is a relatively new field within the larger scope of machine learning. Along with RL, machine learning has two other major subtypes: supervised learning and unsupervised learning. Supervised learning methods, which include classification and linear regression, are given training data of inputs and outputs which are provided by a `knowledgeable external supervisor'. While supervised learning is a popular method that can produce very accurate results, it isn't easily scalable, as correctly labelled data becomes more difficult to source with more complex information. Unsupervised learning, on the other hand, finds structure within collections of unlabelled data. While unsupervised learning methods, such as deep learning and clustering, can work in real time and work with unlabelled data, the results aren't always as accurate as required.

Reinforcement learning (RL) is the third subset of machine learning. In reinforcement learning, a learning agent develops policies that map states of the environment to actions, in order to maximise a numerical reward. Unlike supervised learning, the agent is not given any labelled examples, and unlike unsupervised learning, reinforcement learning is given a reward when a desirable outcome is achieved. RL algorithms produce policies by interacting with the environment in a trial and error fashion, in real time. 

Reinforcement learning does not require any pre-provided training data, and does not need to discover any hidden structure. Reinforcement learning, simply put, decides the optimal actions given a situation to maximize reward. Reinforcement learning has been used for a variety of problems and situations, including playing the board game Go\cite{Silver2017}, cooling data centres \cite{DBLP:journals/corr/abs-1709-05077}, and finding the optimal medication dosing for new medicines\cite{7591355}. It can operate with only a minimal understanding of its environment's structure, does not need any previous examples of how to act, and can can adapt to environments that change behaviour over time. Most importantly, because reinforcement learning works with situations that involve delayed rewards, these algorithms will work optimally with distributed systems, where multiple services will need to be accessed to reach the desired goal.

The next chapter of this dissertation discusses the major aims and objectives for this project, and the third chapter gives an overview of the basic reinforcement learning knowledge that is necessary for the rest of the dissertation. The problem description section gives structure to the environment this project aims to solve, and the approach and application sections describe how the solution was found. Finally, the results, analysis, conclusion and reflection sections follow.






